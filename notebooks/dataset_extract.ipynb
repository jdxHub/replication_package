{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "b_wQrF_Am67j",
        "CAzR3Fh0pxsD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Install V-SZZ"
      ],
      "metadata": {
        "id": "b_wQrF_Am67j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/baolingfeng/V-SZZ.git"
      ],
      "metadata": {
        "id": "pZIO1lGCB-0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/V-SZZ/ICSE2022ReplicationPackage/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "LutEyXGCEmMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/V-SZZ/ICSE2022ReplicationPackage/icse2021-szz-replication-package/tools/pyszz/')"
      ],
      "metadata": {
        "id": "ufgpEeoKFXDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create dataset"
      ],
      "metadata": {
        "id": "CAzR3Fh0pxsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title create dataset\n",
        "from szz.my_szz import MySZZ\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import git\n",
        "import io\n",
        "from pydriller import ModificationType, RepositoryMining, GitRepository\n",
        "from typing import List, Set\n",
        "import itertools\n",
        "import time\n",
        "\n",
        "def copyfile(commit_file, target):\n",
        "  Path(target).parent.mkdir(parents=True, exist_ok=True)\n",
        "  with io.BytesIO(commit_file.data_stream.read()) as f:\n",
        "    with open(target, 'wb') as t:\n",
        "      t.write(f.read())\n",
        "\n",
        "import requests\n",
        "import re\n",
        "\n",
        "def getRename(url_path, commit):\n",
        "  sendData = [\n",
        "      ('items[item-0][current_blob_path]', url_path),\n",
        "      ('items[item-0][last_commit]', commit),\n",
        "      ('items[item-0][branch]', 'master'),\n",
        "      ('items[item-0][new_path]', url_path),\n",
        "      ('_method', 'GET')\n",
        "  ]\n",
        "\n",
        "  response = requests.post('https://github.com/torvalds/linux/commits/check_for_rename_commits', headers={\"x-requested-with\": \"XMLHttpRequest\"}, data=sendData)\n",
        "  return re.search('Renamed from (.+)\\\\\\\\n      <a', response.text)\n",
        "\n",
        "def findOldName(current_commit, file_path, base_url='https://github.com/torvalds/linux/commits/'):\n",
        "  url = base_url+current_commit+'/'+file_path\n",
        "  while url:\n",
        "    res = requests.get(url)\n",
        "    \n",
        "    while 'Retry-After' in res.headers:\n",
        "      time.sleep(int(res.headers[\"Retry-After\"]))\n",
        "      print('retry')\n",
        "      res = requests.get(url)\n",
        "    page = res.text\n",
        "    next = re.search('Newer(</a>|</button>)<a rel=\"nofollow\" class=\"btn btn-outline BtnGroup-item\" href=\"(.+)\">Older</a>', page)\n",
        "    if next:\n",
        "      url = next.group(2)\n",
        "    else:\n",
        "      print(current_commit, file_path)\n",
        "      try:\n",
        "        rename = getRename(file_path,re.findall('data-url=\"/torvalds/linux/commits/(.+)/commits_list_item\"', page)[-1])\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        print(url)\n",
        "        print(page)\n",
        "        exit()\n",
        "      if rename:\n",
        "        return rename.group(1)\n",
        "      else:\n",
        "        return None\n",
        "\n",
        "repo_url='https://github.com/torvalds/linux'\n",
        "   \n",
        "\n",
        "my_szz = MySZZ(repo_full_name='torvalds/linux', repo_url=repo_url, repos_dir='/content/repo', ast_map_path=None)\n",
        "repository = git.Repo(os.path.join('/content/repo', 'torvalds/linux'))\n",
        "log_txt = os.path.join('/content/dataset', 'linux_kernel', 'last_commit.txt')\n",
        "Path(log_txt).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for data_file in os.listdir('/content/data'):\n",
        "  if os.path.isdir(os.path.join('/content/data',data_file)):\n",
        "      continue\n",
        "  print(data_file)\n",
        "  with open(os.path.join('/content/data',data_file)) as data:\n",
        "\n",
        "    data_json = json.load(data)\n",
        "    \n",
        "    for fix in data_json:\n",
        "      \n",
        "            inducings = list(set([(commit['previous_commits'][-1][0], commit['file_path']) for commit in data_json[fix]]))\n",
        "            if len(inducings) == 0:\n",
        "              continue\n",
        "            if len(inducings) > 1:\n",
        "              print('More than 1 inducing commit?? %s' % inducings)\n",
        "            for inducing in inducings:\n",
        "              inducing_hash, file_path = inducing\n",
        "              print(file_path)\n",
        "              print('Fixing Commit:', fix)\n",
        "              print('Inducing Commit:', inducing_hash)\n",
        "              with open(log_txt, 'w') as f:\n",
        "                f.write('fix: %s, inducing: %s, data file: %s' % (fix, inducing_hash, data_file))\n",
        "              \n",
        "              Directory = os.path.join('/content/dataset', 'linux_kernel', inducing_hash)\n",
        "              \n",
        "          \n",
        "  \n",
        "              inducing_commit = repository.commit(inducing_hash)\n",
        "              try:\n",
        "                pre_inducing_commit = repository.commit(inducing_hash+'~1')\n",
        "              except:\n",
        "                pre_inducing_commit = None\n",
        "\n",
        "\n",
        "  \n",
        "              pre_inducing_file = None\n",
        "              old_path = None\n",
        "              try:\n",
        "                inducing_file = inducing_commit.tree / file_path\n",
        "              except Exception as e:\n",
        "                old_path = findOldName(fix, file_path)\n",
        "                if old_path is None:\n",
        "                  print('----ERROR----')\n",
        "                  print(e)\n",
        "                  continue\n",
        "                try:\n",
        "                  inducing_file = inducing_commit.tree / old_path\n",
        "                except:\n",
        "                  print('abort')\n",
        "                  continue\n",
        "\n",
        "              if pre_inducing_commit is not None:\n",
        "                try:\n",
        "                  if old_path is None:\n",
        "                    pre_inducing_file = pre_inducing_commit.tree / file_path\n",
        "                  else:\n",
        "                    pre_inducing_file = pre_inducing_commit.tree / old_path\n",
        "                except Exception as e:\n",
        "                  old_path = findOldName(inducing_hash, file_path if old_path is None else old_path)\n",
        "                  if old_path is None:    \n",
        "                    print('\\033[92m%s is new in inducing commit\\033[0m' % file_path)\n",
        "                  else:\n",
        "                    print('\\033[96mOld path: %s\\033[0m' % old_path)\n",
        "                    try:\n",
        "                      pre_inducing_file = pre_inducing_commit.tree / old_path\n",
        "                    except:\n",
        "                      print('abort')\n",
        "                      continue\n",
        "\n",
        "              file_path = os.path.basename(file_path)\n",
        "              \n",
        "              if pre_inducing_file is not None:\n",
        "                copyfile(inducing_file, os.path.join(Directory, 'vulnerability_inducing', file_path))\n",
        "                copyfile(pre_inducing_file, os.path.join(Directory, 'pre_vulnerability_inducing', file_path))\n",
        "              else:\n",
        "                copyfile(inducing_file, os.path.join('/content/dataset', 'linux_kernel', 'new', inducing_hash, 'vulnerability_inducing', file_path))"
      ],
      "metadata": {
        "id": "c2_2FoC1frLG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
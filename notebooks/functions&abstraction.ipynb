{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "F2S1wSGbhVHN",
        "mf_elkljiciA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install Dependencies"
      ],
      "metadata": {
        "id": "F2S1wSGbhVHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install srcml\n",
        "!wget https://github.com/srcML/srcMLReleases/raw/main/srcml_1.0.0-1_ubuntu20.04.deb\n",
        "!sudo apt install ./srcml_1.0.0-1_ubuntu20.04.deb"
      ],
      "metadata": {
        "id": "CT_9ubg-eu5C",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install src2abs\n",
        "!git clone https://github.com/micheletufano/src2abs.git\n",
        "!sudo apt-get install maven\n",
        "%cd src2abs\n",
        "!mvn clean\n",
        "!mvn install:install-file -Dfile=\"lib/javalexer.jar\" -DgroupId=\"edu.wm.cs\" -DartifactId=\"javalexer\" -Dversion=\"1\" -Dpackaging=\"jar\"\n",
        "!mvn package\n",
        "!mv target/src2abs-0.1-jar-with-dependencies.jar /content/src2abs-0.1-jar-with-dependencies.jar\n",
        "%cd /content/\n"
      ],
      "metadata": {
        "id": "oFidnWuPFRff",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Parameters"
      ],
      "metadata": {
        "id": "dBFdQzyMhe8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Paths parameters\n",
        "#@markdown Path to the dataset with source code files\n",
        "raw_files_dataset_path = '/content/raw_dataset/' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown Path to store paths to every files to abstract.\n",
        "output_paths_dataframe = '/content/functions_dataset_paths.csv' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown Path to store the abstracted functions\n",
        "functions_dataset_path = '/content/functions_dataset/' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RiDEfhhuvB3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run"
      ],
      "metadata": {
        "id": "mf_elkljiciA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Splitting parameters. Used to split the functions dataset generation between multiple colab instances (optional)\n",
        "\n",
        "split_amount = 1 #@param {type:\"slider\", min:1, max:10}\n",
        "#@markdown ---\n",
        "#@markdown Part to be used for the current instance of colab (from 0 to split_amount excluded)\n",
        "current_part = 0 #@param {type:\"integer\"}\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E1lRCsKJxE8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title generate and save paths\n",
        "import os\n",
        "import pandas as pd\n",
        "if not os.path.exists(output_paths_dataframe):\n",
        "  paths = []\n",
        "  for root, subdirs, files in os.walk(raw_files_dataset_path):\n",
        "    new_root=root.replace(raw_files_dataset_path, '')\n",
        "    if 'pre_patch' in new_root or 'pre_vulnerability_inducing' in new_root or '/new/' in new_root:\n",
        "      continue\n",
        "    for f in files:\n",
        "      if f == 'last_commit.txt':\n",
        "        continue\n",
        "      paths.append(os.path.join(new_root,f))\n",
        "\n",
        "  df = pd.DataFrame(paths)\n",
        "  df.to_csv(output_paths_dataframe, index=False)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nhlJWBk7pucK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load paths\n",
        "pathsdf = pd.read_csv(output_paths_dataframe)\n"
      ],
      "metadata": {
        "id": "4p8VQNhdybmr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title splitting (for multiple colab instances)\n",
        "import numpy as np\n",
        "pathsdf = np.array_split(pathsdf, split_amount)[current_part]"
      ],
      "metadata": {
        "id": "Arhlf2kN7KQ9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run parsing\n",
        "import os\n",
        "import subprocess\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "\n",
        "srcML = {'s':'http://www.srcML.org/srcML/src'}\n",
        "\n",
        "def function_generation_raw(function_txt, new_root, function_name, f):\n",
        "      \n",
        "      filename, ext = os.path.splitext(f)\n",
        "      new_root_raw = os.path.join(raw_files_dataset_path, 'raw', new_root, '%s_func_%s%s' % (filename, function_name, ext))\n",
        "      \n",
        "      Path(new_root_raw).parent.mkdir(parents=True, exist_ok=True)\n",
        "      with open(new_root_raw, 'wb') as out:\n",
        "        out.write(function_txt)\n",
        "\n",
        "      return new_root_raw\n",
        "\n",
        "def function_generation_abs(raw_1, raw_2):\n",
        "\n",
        "      abstract_1 = raw_1.replace('/raw/', '/abstract/')\n",
        "      abstract_2 = raw_2.replace('/raw/', '/abstract/')\n",
        "      Path(abstract_1).parent.mkdir(parents=True, exist_ok=True)\n",
        "      Path(abstract_2).parent.mkdir(parents=True, exist_ok=True)\n",
        "      result = subprocess.run(['java', '-jar', 'src2abs-0.1-jar-with-dependencies.jar', 'pair', 'method', raw_1, raw_2, abstract_1, abstract_2, 'src2abs/idioms/idioms.csv'])\n",
        "      if result.returncode != 0:\n",
        "        print('ERROR', raw_1, raw_2, abstract_1, abstract_2, result.returncode)\n",
        "\n",
        "def function_generation_abs_single(raw):\n",
        "\n",
        "      abstract = raw.replace('/raw/', '/abstract/')\n",
        "      Path(abstract).parent.mkdir(parents=True, exist_ok=True)\n",
        "      result = subprocess.run(['java', '-jar', 'src2abs-0.1-jar-with-dependencies.jar', 'single', 'method', raw, abstract, 'src2abs/idioms/idioms.csv'])\n",
        "      if result.returncode != 0:\n",
        "        print('ERROR', raw, abstract, result.returncode)\n",
        "\n",
        "def parse_file(root, file_type, functions):\n",
        "    xmlcontent = subprocess.check_output(['srcml', root.replace('vulnerability_inducing', file_type)])\n",
        "    tree = ET.fromstring(xmlcontent)\n",
        "    for function in tree.iterfind('s:function', srcML):\n",
        "      function_name = function.find('s:name', srcML).text\n",
        "      if not function_name in functions:\n",
        "        functions[function_name] = {}\n",
        "      functions[function_name][file_type] = function\n",
        "\n",
        "def getfunction_txt(versions, version_type):\n",
        "  version = versions.get(version_type)\n",
        "  if version is None:\n",
        "    return None\n",
        "  return ET.tostring(version, encoding='utf8', method='text')\n",
        "\n",
        "VERSION_TYPES = ('vulnerability_inducing', 'pre_vulnerability_inducing')\n",
        "\n",
        "for row in pathsdf.iterrows():\n",
        "  new_root = row[1].values[0]\n",
        "  check_output_dir = functions_dataset_path+'/'.join(new_root.split('/')[:-2])\n",
        "  if os.path.exists(check_output_dir):\n",
        "    print('%s already exists' % check_output_dir)\n",
        "    continue\n",
        "  print(new_root)\n",
        "  functions = {}\n",
        "  for version_type in VERSION_TYPES:\n",
        "    parse_file(os.path.join(raw_files_dataset_path,new_root), version_type, functions)\n",
        "  file_name = os.path.basename(new_root);\n",
        "  for function_name in functions:\n",
        "    versions = functions[function_name]\n",
        "    if len(versions) < len(VERSION_TYPES):\n",
        "      print('%s is missing in %s' % (function_name, str([version_type for version_type in VERSION_TYPES if version_type not in versions ])))\n",
        "\n",
        "    patch = getfunction_txt(versions,'patch')\n",
        "    pre_patch = getfunction_txt(versions,'pre_patch')\n",
        "    vulnerability_inducing = getfunction_txt(versions,'vulnerability_inducing')\n",
        "    pre_vulnerability_inducing = getfunction_txt(versions,'pre_vulnerability_inducing')\n",
        "\n",
        "    if patch is not None and pre_patch is not None:\n",
        "      final_root = None\n",
        "      if patch != pre_patch:\n",
        "        final_root = new_root.replace('patch', 'pre_patch_patch_diff')\n",
        "        patch_root = function_generation_raw(patch, final_root, '%s_%s' % (function_name, 'patch'), file_name)\n",
        "        pre_patch_root = function_generation_raw(pre_patch, final_root, '%s_%s' % (function_name, 'pre_patch'), file_name)\n",
        "        function_generation_abs(patch_root, pre_patch_root)\n",
        "      else:\n",
        "        final_root = new_root.replace('patch', 'pre_patch_patch_same')\n",
        "        function_generation_abs_single(function_generation_raw(patch, final_root, function_name, file_name))\n",
        "    else:\n",
        "      for version_type in ('patch', 'pre_patch'):\n",
        "        function = getfunction_txt(versions,version_type)\n",
        "        if function is not None:\n",
        "          function_generation_abs_single(function_generation_raw(function, new_root.replace('patch', version_type), function_name, file_name))\n",
        "    \n",
        "    if pre_vulnerability_inducing is not None and vulnerability_inducing is not None:\n",
        "      final_root = None\n",
        "      if pre_vulnerability_inducing != vulnerability_inducing:\n",
        "        final_root = new_root.replace('vulnerability_inducing', 'pre_vulnerability_inducing_vulnerability_inducing_diff')\n",
        "        pre_vulnerability_inducing_root = function_generation_raw(pre_vulnerability_inducing, final_root, '%s_%s' % (function_name, 'pre_vulnerability_inducing'), file_name)\n",
        "        vulnerability_inducing_root = function_generation_raw(vulnerability_inducing, final_root, '%s_%s' % (function_name, 'vulnerability_inducing'), file_name)\n",
        "        function_generation_abs(vulnerability_inducing_root, pre_vulnerability_inducing_root)\n",
        "      else:\n",
        "        final_root = new_root.replace('vulnerability_inducing', 'pre_vulnerability_inducing_vulnerability_inducing_same')\n",
        "        function_generation_abs_single(function_generation_raw(vulnerability_inducing, final_root, function_name, file_name))\n",
        "\n",
        "    else:\n",
        "      for version_type in ('pre_vulnerability_inducing', 'vulnerability_inducing'):\n",
        "        function = getfunction_txt(versions,version_type)\n",
        "        if function is not None:\n",
        "          function_generation_abs_single(function_generation_raw(function, new_root.replace('vulnerability_inducing', version_type), function_name, file_name))\n",
        "    "
      ],
      "metadata": {
        "id": "XGMhHVvgA7Zz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}